{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd073fdd517862a664a96a081812e62a16a90ccf7f8abe555ad9995abe92cfb7ff3",
   "display_name": "Python 3.8.5 64-bit ('data analysis': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import os\n",
    "import glob\n",
    "from Action_Segmentation import *\n",
    "from Feature_Engineer import *\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "from datetime import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "os.chdir(\"C:\\\\Users\\\\Andrius\\\\Downloads\\\\Mouse-Dynamics-Challenge-master\\\\Mouse-Dynamics-Challenge-master\")\n",
    "train=pd.read_csv('train_save_pre_seg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'record timestamp', 'client timestamp',\n",
       "       'button', 'state', 'x', 'y', 'session', 'user'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def action_row(row):\n",
    "    if row['state']=='Released' and row['state_lag']=='Drag':\n",
    "        return 'DD'\n",
    "    elif row['state']=='Released' and row['state_lag']=='Pressed':\n",
    "        return 'PC'\n",
    "    \n",
    "def delta_maker(data):\n",
    "    temp=pd.DataFrame()\n",
    "    \n",
    "    temp=data[(data['Action']=='DD') | (data['Action']=='PC') | (data['Action']=='MM')]\n",
    "    \n",
    "    data.loc[:,'action_begin']=temp['client timestamp'].shift()\n",
    "    data.loc[data.index[0],'action_begin']=data['client timestamp'].values[0]\n",
    "    data.loc[temp['client timestamp'].index[0],'action_begin']=data['client timestamp'].iloc[0]\n",
    "    \n",
    "    data.loc[:,'delta_action']=temp['client timestamp']-data['action_begin']\n",
    "    \n",
    "    \n",
    "    temp['index']=temp.index\n",
    "    \n",
    "    temp['begin_act_idx']=temp['index'].shift()\n",
    "    \n",
    "    temp.loc[temp.index[0],'begin_act_idx']=data.index[0]\n",
    "    \n",
    "    temp.set_index(temp['index'],inplace=True)\n",
    "    \n",
    "    #temp.columns.name=None\n",
    "    data.loc[:,'begin_act_idx']=data.merge(temp,how='left',left_index=True, right_index=True)['begin_act_idx']\n",
    "   \n",
    "def post_seg_delta_maker(data):\n",
    "    \n",
    "    data.loc[:,'action_begin']=data[(data['Action_border']=='DD') | (data['Action_border']=='PC') | (data['Action_border']=='MM')]['client timestamp'].shift()\n",
    "    \n",
    "    data.loc[data[(data['Action_border']=='DD') | (data['Action_border']=='PC') | (data['Action_border']=='MM')]['client timestamp'].index[0],'action_begin']=data['client timestamp'].iloc[0]\n",
    "    #data[(data['Action']=='DD') | (data['Action']=='PC')].reset_index(drop=True).loc[0,'action_begin']=data['client timestamp'].loc[0]\n",
    "    data.loc[:,'delta_action']=data[(data['Action_border']=='DD') | (data['Action_border']=='PC') | (data['Action_border']=='MM')]['client timestamp']-data['action_begin']\n",
    "    \n",
    "def closest_timestamp(row,data,min_events):\n",
    "    \n",
    "    temp=(data['client timestamp']-row['action_corrector']).abs().sort_values().index[0]\n",
    "    \n",
    "    #Considerar minimo de eventos\n",
    "    if row.name-temp >= min_events :\n",
    "        data.loc[temp,'Action']='MM'\n",
    "        data.loc[row.name,'act_correc_index']=temp\n",
    "    \n",
    "        \n",
    "def action_mm_finder(data,thresh,min_events):    \n",
    "    # 1- Calcular time -resto(delta/10)\n",
    "    data['action_corrector']=data['client timestamp']-data['delta_action']%thresh\n",
    "    \n",
    "    #-2 Função para para procurar índice da linha mais proxima do valor\n",
    "    data[data['delta_action']>=thresh].apply(closest_timestamp,args=(data,min_events),axis=1)\n",
    "    \n",
    "        \n",
    "def correct_small_actions(row,min_events):\n",
    "    \n",
    "    if row.Action_border!=None and row.Action_border_lag!=None :\n",
    "\n",
    "        return row.Action_border_lag\n",
    "    else:\n",
    "        if row.name-row.begin_act_idx < min_events:\n",
    "            return None\n",
    "        else:\n",
    "            return row.Action_border\n",
    "    \n",
    "\n",
    "def correct_small_actions_2(row):\n",
    "    \n",
    "    if row.Action_border!=None and row.Action_border_antilag!=None and pd.notna(row.Action_border_antilag): \n",
    "        return None\n",
    "    else:\n",
    "        return row.Action_border\n",
    "    \n",
    "\n",
    "    \n",
    "def segmentation(data2,thresh,min_events):\n",
    "    \n",
    "    data=data2.copy(deep=True)\n",
    "    data['state_lag']=data['state'].shift()\n",
    "    data.loc[:,'Action']=data.apply(action_row,axis=1)\n",
    "    delta_maker(data)\n",
    "    action_mm_finder(data,thresh,min_events)\n",
    "    if data.Action.iloc[[-1]].item() != 'PC' and data.Action.iloc[[-1]].item() != 'DD':\n",
    "        data.loc[data.index[-1],'Action']='MM'\n",
    "\n",
    "    \n",
    "    data['Action_border']=data['Action']\n",
    "    data['Action_border_lag']=data['Action_border'].shift()\n",
    "    data['Action_border']=data.apply(correct_small_actions,args=(min_events,),axis=1)\n",
    "    \n",
    "    data['Action_border_antilag']=data['Action_border'].shift(-1)\n",
    "    data['Action_border']=data.apply(correct_small_actions_2,axis=1)\n",
    "    data.loc[data.index[-1],'Action_border']=data.Action.iloc[[-1]].values[0]\n",
    "    data['Action']=data.Action.fillna(method='bfill')\n",
    "    data.drop(['Action_border_lag','Action_border_antilag'],axis=1,inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "#Função para tratar train_seg:\n",
    "def segmentation_prep(data):\n",
    "    data=data.drop(['state_lag','action_corrector'],axis=1)\n",
    "\n",
    "    post_seg_delta_maker(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-20-10518e831677>:22: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  temp['index']=temp.index\n<ipython-input-20-10518e831677>:24: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  temp['begin_act_idx']=temp['index'].shift()\nC:\\Users\\Andrius\\anaconda\\envs\\data analysis\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "train_seg=pd.DataFrame()\n",
    "thresh=10\n",
    "min_events=4\n",
    "\n",
    "\n",
    "train_seg=train_seg.append(segmentation(train[train.session=='session_1658051584'],thresh,min_events))\n",
    "train_seg=segmentation_prep(train_seg)\n",
    "train_save=train_seg\n",
    "#train_seg=segmentation_prep(train_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "488329    None\n",
       "488330    None\n",
       "488331    None\n",
       "488332    None\n",
       "488333    None\n",
       "          ... \n",
       "525788    None\n",
       "525789    None\n",
       "525790      PC\n",
       "525791    None\n",
       "525792      PC\n",
       "Name: Action_border, Length: 37464, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "train_seg.Action_border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: Float64Index([nan, nan], dtype='float64'). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-6b2cffce53d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_seg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_seg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'begin_act_idx'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda\\envs\\data analysis\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    887\u001b[0m                     \u001b[1;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\envs\\data analysis\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIndexingError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1060\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1061\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m         \u001b[1;31m# no multi-index, so validate all of the indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\envs\\data analysis\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    829\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0msection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m                 \u001b[1;31m# This is an elided recursive call to iloc/loc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 831\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    832\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"not applicable\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\envs\\data analysis\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\envs\\data analysis\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1111\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1113\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1115\u001b[0m             \u001b[1;31m# nested tuple slicing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\envs\\data analysis\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# A collection of keys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1053\u001b[1;33m         \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1054\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[0;32m   1055\u001b[0m             \u001b[1;33m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\envs\\data analysis\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1266\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\envs\\data analysis\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"display.max_seq_items\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"display.width\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m80\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m                 raise KeyError(\n\u001b[0m\u001b[0;32m   1322\u001b[0m                     \u001b[1;34m\"Passing list-likes to .loc or [] with any missing labels \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m                     \u001b[1;34m\"is no longer supported. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: Float64Index([nan, nan], dtype='float64'). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\""
     ]
    }
   ],
   "source": [
    "train_seg.loc[train_seg.loc[:,'begin_act_idx'].values,'x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seg=train_save\n",
    "temp=pd.DataFrame()\n",
    "#train_seg=train_seg[train_seg.session=='session_5265929106']\n",
    "temp=pd.DataFrame((train_seg[(train_seg.Action_border=='PC')| (train_seg.Action_border=='MM') | (train_seg.Action_border=='DD')].Action_border.index))\n",
    "temp['action_count']=temp.index\n",
    "temp['index']=temp.loc[:,0]\n",
    "temp.drop(0,axis=1,inplace= True)\n",
    "temp.set_index(temp['index'],inplace=True)\n",
    "temp.columns.name=None\n",
    "train_seg=train_seg.merge(temp,how='left',left_index=True, right_index=True)\n",
    "train_seg['action_count'].fillna(method='bfill',inplace=True)\n",
    "#train_seg.drop('index',axis=1,inplace=True)\n",
    "#2nd dataframe with action features\n",
    "df_action=train_seg[train_seg.Action_border.notna()].copy(deep=True)\n",
    "df_action['index']=train_seg[train_seg.Action_border.notna()].index\n",
    "df_action['begin_act_idx']=df_action['index'].shift()\n",
    "df_action.loc[df_action.index[0],'begin_act_idx']=train_seg.index[0]\n",
    "train_seg.loc[:,'begin_act_idx']=df_action['begin_act_idx']\n",
    "    ###########################################################\n",
    "    #############################################################\n",
    "train_seg.loc[:,'begin_act_idx'].fillna(method='bfill',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "488329    488329.0\n",
       "488330    488329.0\n",
       "488331    488329.0\n",
       "488332    488329.0\n",
       "488333    488329.0\n",
       "            ...   \n",
       "525788    525764.0\n",
       "525789    525764.0\n",
       "525790    525764.0\n",
       "525791    525790.0\n",
       "525792    525790.0\n",
       "Name: begin_act_idx, Length: 37464, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "train_seg['begin_act_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "488478    488329.0\n",
       "488506    488478.0\n",
       "488535    488506.0\n",
       "488545    488535.0\n",
       "488553    488545.0\n",
       "            ...   \n",
       "525737    525727.0\n",
       "525743    525737.0\n",
       "525751    525743.0\n",
       "525764    525751.0\n",
       "525790    525764.0\n",
       "Name: begin_act_idx, Length: 2027, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "df_action['begin_act_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "488329    None\n",
       "488330    None\n",
       "488331    None\n",
       "488332    None\n",
       "488333    None\n",
       "          ... \n",
       "525788    None\n",
       "525789    None\n",
       "525790      PC\n",
       "525791    None\n",
       "525792    None\n",
       "Name: Action_border, Length: 37464, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "train_seg.Action_border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Euclidean_Dist(df1, df2):\n",
    "    return np.linalg.norm(df1.values - df2.values,\n",
    "                   axis=1)\n",
    "#Função distancia segmento/ponto\n",
    "def lineseg_dists(p, a, b):\n",
    "    \"\"\"Cartesian distance from point to line segment\n",
    "\n",
    "    Edited to support arguments as series, from:\n",
    "    https://stackoverflow.com/a/54442561/11208892\n",
    "\n",
    "    Args:\n",
    "        - p: np.array of single point, shape (2,) or 2D array, shape (x, 2)\n",
    "        - a: np.array of shape (x, 2)\n",
    "        - b: np.array of shape (x, 2)\n",
    "    \"\"\"\n",
    "    # normalized tangent vectors\n",
    "    d_ba = b - a\n",
    "    d = np.divide(d_ba, (np.hypot(d_ba[:, 0], d_ba[:, 1])\n",
    "                           .reshape(-1, 1)))\n",
    "    #np.nan_to_num(d,copy=False,nan=[0,0])\n",
    "    #print(np.isnan(d).sum())\n",
    "\n",
    "    # signed parallel distance components\n",
    "    # rowwise dot products of 2D vectors\n",
    "    s = np.multiply(a - p, d).sum(axis=1)\n",
    "    t = np.multiply(p - b, d).sum(axis=1)\n",
    "\n",
    "    # clamped parallel distance\n",
    "    h = np.maximum.reduce([s, t, np.zeros(len(s))])\n",
    "\n",
    "    # perpendicular distance component\n",
    "    # rowwise cross products of 2D vectors  \n",
    "    d_pa = p - a\n",
    "    #print(c)\n",
    "    c = d_pa[:, 0] * d[:, 1] - d_pa[:, 1] * d[:, 0]\n",
    "\n",
    "    return np.hypot(h, c)\n",
    "def feat_eng(train_seg):\n",
    "    temp=pd.DataFrame()\n",
    "    #train_seg=train_seg[train_seg.session=='session_5265929106']\n",
    "    temp=pd.DataFrame((train_seg[(train_seg.Action_border=='PC')| (train_seg.Action_border=='MM') | (train_seg.Action_border=='DD')].Action_border.index))\n",
    "    temp['action_count']=temp.index\n",
    "    temp['index']=temp.loc[:,0]\n",
    "    temp.drop(0,axis=1,inplace= True)\n",
    "    temp.set_index(temp['index'],inplace=True)\n",
    "    temp.columns.name=None\n",
    "    train_seg=train_seg.merge(temp,how='left',left_index=True, right_index=True)\n",
    "    train_seg['action_count'].fillna(method='bfill',inplace=True)\n",
    "    #train_seg.drop('index',axis=1,inplace=True)\n",
    "\n",
    "    #2nd dataframe with action features\n",
    "\n",
    "    df_action=train_seg[train_seg.Action_border.notna()].copy(deep=True)\n",
    "    df_action['index']=train_seg[train_seg.Action_border.notna()].index\n",
    "    df_action['begin_act_idx']=df_action['index'].shift()\n",
    "    df_action['action_count']=train_seg['action_count']\n",
    "    df_action.loc[df_action.index[0],'begin_act_idx']=train_seg.index[0]\n",
    "    train_seg.loc[:,'begin_act_idx']=df_action['begin_act_idx']\n",
    "    ###########################################################\n",
    "    #############################################################\n",
    "    train_seg.loc[:,'begin_act_idx'].fillna(method='bfill',inplace=True)\n",
    "    train_seg.loc[:,'end_act_idx']=df_action['index']\n",
    "    train_seg.loc[:,'end_act_idx'].fillna(method='bfill',inplace=True)\n",
    "    df_action.loc[df_action.index.to_list()[0],'begin_act_idx']=0\n",
    "\n",
    "\n",
    "    #delta x,y, t\n",
    "    train_seg['delta_x']=train_seg['x']-train_seg['x'].shift()\n",
    "    train_seg['delta_y']=train_seg['y']-train_seg['y'].shift()\n",
    "    train_seg.loc[train_seg.index[0],'delta_x']=0\n",
    "    train_seg.loc[train_seg.index[0],'delta_y']=0\n",
    "    #print(train_seg.loc[:,'begin_act_idx'].values)\n",
    "    #train_seg['delta_x_begin_act']=np.sqrt((train_seg['x'].values-train_seg.loc[train_seg.loc[:,'begin_act_idx'].values,'x'].values)**2+(train_seg['y'].values-train_seg.loc[train_seg.loc[:,'begin_act_idx'].values,'y'].values)**2)\n",
    "    #train_seg['delta_x_end_act']=np.sqrt((train_seg['x'].values-train_seg.loc[train_seg.loc[:,'end_act_idx'].values,'x'].values)**2+(train_seg['y'].values-train_seg.loc[train_seg.loc[:,'end_act_idx'].values,'y'].values)**2)\n",
    "    #print(np.array(list(zip(train_seg.loc[train_seg.loc[:,'begin_act_idx'].values,'x'],train_seg.loc[train_seg.loc[:,'begin_act_idx'].values,'y']))))\n",
    "    train_seg['deviation']=lineseg_dists(p=np.array(train_seg[['x','y']]),\n",
    "                                         a=np.array(list(zip(train_seg.loc[train_seg.loc[:,'begin_act_idx'].values,'x'],train_seg.loc[train_seg.loc[:,'begin_act_idx'].values,'y']))),\n",
    "                                         b=np.array(list(zip(train_seg.loc[train_seg.loc[:,'end_act_idx'].values,'x'],train_seg.loc[train_seg.loc[:,'end_act_idx'].values,'y']))))  \n",
    "    \n",
    "    train_seg['dist_from_act_init']=Euclidean_Dist(train_seg.loc[train_seg['begin_act_idx'],['x','y']],\n",
    "    train_seg[['x','y']])\n",
    "    train_seg.deviation.fillna(train_seg['dist_from_act_init'],inplace=True)\n",
    "    \n",
    "    \n",
    "    #Tempo\n",
    "    train_seg['delta_t']=(train_seg['client timestamp']-train_seg['client timestamp'].shift())\n",
    "    train_seg['delta_t'].replace(0, train_seg[train_seg['delta_t']!=0].delta_t.min()/2,inplace=True)\n",
    "    train_seg.loc[train_seg.index[0],'delta_t']=0\n",
    "    \n",
    "    #Velo\n",
    "    train_seg['vel_x']=train_seg['delta_x']/train_seg['delta_t']\n",
    "    train_seg.loc[train_seg.index[0],'vel_x']=0    \n",
    "    train_seg['vel_x_delta']=train_seg['vel_x']-train_seg['vel_x'].shift()\n",
    "    train_seg.loc[train_seg.index[0],'vel_x_delta']=0    \n",
    "    #velocidades \n",
    "    train_seg['vel_y']=train_seg['delta_y']/train_seg['delta_t']\n",
    "    train_seg.loc[train_seg.index[0],'vel_y']=0    \n",
    "    train_seg.loc[:,'vel_y'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    train_seg['vel_y_delta']=train_seg['vel_y']-train_seg['vel_y'].shift()\n",
    "    train_seg.loc[train_seg.index[0],'vel_y_delta']=0    \n",
    "    train_seg['vel_total']=np.sqrt(np.power(train_seg['vel_x'],2)+np.power(train_seg['vel_y'],2))\n",
    "    train_seg.loc[train_seg.index[0],'vel_total']=0    \n",
    "    train_seg['vel_tot_delta']=train_seg['vel_total']-train_seg['vel_total'].shift()\n",
    "    train_seg.loc[train_seg.index[0],'vel_tot_delta']=0\n",
    "    #theta coordenada angular\n",
    "    train_seg['theta']=np.arctan(train_seg['delta_y']/train_seg['delta_x'])\n",
    "    train_seg['theta'].replace(np.nan,0, inplace=True)\n",
    "    train_seg.loc[train_seg.index[0],'theta']=0\n",
    "    train_seg['theta_delta']=train_seg['theta']-train_seg['theta'].shift()\n",
    "    train_seg.loc[train_seg.index[0],'theta_delta']=0 \n",
    "    #extras\n",
    "    train_seg['acc']=train_seg['vel_tot_delta']/train_seg['delta_t']\n",
    "    train_seg.loc[train_seg.index[0],'acc']=0 \n",
    "    train_seg['acc_delta']=train_seg['acc']-train_seg['acc'].shift()\n",
    "    train_seg.loc[train_seg.index[0],'acc_delta']=0  \n",
    "    train_seg['jerk']=train_seg['acc_delta']/train_seg['delta_t']\n",
    "    train_seg.loc[train_seg.index[0],'jerk']=0\n",
    "    #velocidade angular\n",
    "    train_seg['vel_angular']=train_seg['theta_delta']/train_seg['delta_t']\n",
    "    train_seg.loc[train_seg.index[0],'vel_angular']=0\n",
    "\n",
    "    #Curvature\n",
    "    train_seg['event_length']=np.sqrt(np.power(train_seg['delta_x'],2)+np.power(train_seg['delta_y'],2))\n",
    "    train_seg['cum_length']=train_seg['event_length'].cumsum()  \n",
    "\n",
    "    train_seg['cum_length_delta']=train_seg['cum_length']-train_seg['cum_length'].shift()\n",
    "    train_seg.loc[train_seg.index[0],'cum_length_delta']=0   \n",
    "\n",
    "    train_seg['curvat']=train_seg['theta_delta']/train_seg['delta_t']\n",
    "    train_seg.loc[train_seg.index[0],'curvat']=0\n",
    "    #Action Dataframe\n",
    "    #df_action=train_seg[train_seg.Action_border.notna()].copy(deep=True)\n",
    "    #df_action['begin_act_idx']=[0]+df_action.index.to_list()\n",
    "    df_action['v_x_mean']=df_action.merge(train_seg.groupby(by='action_count')['vel_x'].mean(),left_on=['action_count'],right_index=True,how='left')['vel_x']\n",
    "    df_action['v_x_std']=df_action.merge(train_seg.groupby(by='action_count')['vel_x'].std(),left_on=['action_count'],right_index=True,how='left')['vel_x']\n",
    "    df_action['v_x_max']=df_action.merge(train_seg.groupby(by='action_count')['vel_x'].max(),left_on=['action_count'],right_index=True,how='left')['vel_x']\n",
    "    df_action['v_x_min']=df_action.merge(train_seg.groupby(by='action_count')['vel_x'].min(),left_on=['action_count'],right_index=True,how='left')['vel_x']\n",
    "\n",
    "    df_action['v_y_mean']=df_action.merge(train_seg.groupby(by='action_count')['vel_y'].mean(),left_on=['action_count'],right_index=True,how='left')['vel_y']\n",
    "    df_action['v_y_std']=df_action.merge(train_seg.groupby(by='action_count')['vel_y'].std(),left_on=['action_count'],right_index=True,how='left')['vel_y']\n",
    "    df_action['v_y_max']=df_action.merge(train_seg.groupby(by='action_count')['vel_y'].max(),left_on=['action_count'],right_index=True,how='left')['vel_y']\n",
    "    df_action['v_y_min']=df_action.merge(train_seg.groupby(by='action_count')['vel_y'].min(),left_on=['action_count'],right_index=True,how='left')['vel_y']\n",
    "\n",
    "    df_action['v_t_mean']=df_action.merge(train_seg.groupby(by='action_count')['vel_total'].mean(),left_on=['action_count'],right_index=True,how='left')['vel_total']\n",
    "    df_action['v_t_std']=df_action.merge(train_seg.groupby(by='action_count')['vel_total'].std(),left_on=['action_count'],right_index=True,how='left')['vel_total']\n",
    "    df_action['v_t_max']=df_action.merge(train_seg.groupby(by='action_count')['vel_total'].max(),left_on=['action_count'],right_index=True,how='left')['vel_total']\n",
    "    df_action['v_t_min']=df_action.merge(train_seg.groupby(by='action_count')['vel_total'].min(),left_on=['action_count'],right_index=True,how='left')['vel_total'] \n",
    "\n",
    "    df_action['acc_mean']=df_action.merge(train_seg.groupby(by='action_count')['acc'].mean(),left_on=['action_count'],right_index=True,how='left')['acc']\n",
    "    df_action['acc_std']=df_action.merge(train_seg.groupby(by='action_count')['acc'].std(),left_on=['action_count'],right_index=True,how='left')['acc']\n",
    "    df_action['acc_max']=df_action.merge(train_seg.groupby(by='action_count')['acc'].max(),left_on=['action_count'],right_index=True,how='left')['acc']\n",
    "    df_action['acc_min']=df_action.merge(train_seg.groupby(by='action_count')['acc'].min(),left_on=['action_count'],right_index=True,how='left')['acc']\n",
    "\n",
    "    df_action['jerk_mean']=df_action.merge(train_seg.groupby(by='action_count')['jerk'].mean(),left_on=['action_count'],right_index=True,how='left')['jerk']\n",
    "    df_action['jerk_std']=df_action.merge(train_seg.groupby(by='action_count')['jerk'].std(),left_on=['action_count'],right_index=True,how='left')['jerk']\n",
    "    df_action['jerk_max']=df_action.merge(train_seg.groupby(by='action_count')['jerk'].max(),left_on=['action_count'],right_index=True,how='left')['jerk']\n",
    "    df_action['jerk_min']=df_action.merge(train_seg.groupby(by='action_count')['jerk'].min(),left_on=['action_count'],right_index=True,how='left')['jerk']\n",
    "\n",
    "    df_action['w_mean']=df_action.merge(train_seg.groupby(by='action_count')['vel_angular'].mean(),left_on=['action_count'],right_index=True,how='left')['vel_angular']\n",
    "    df_action['w_std']=df_action.merge(train_seg.groupby(by='action_count')['vel_angular'].std(),left_on=['action_count'],right_index=True,how='left')['vel_angular']\n",
    "    df_action['w_max']=df_action.merge(train_seg.groupby(by='action_count')['vel_angular'].max(),left_on=['action_count'],right_index=True,how='left')['vel_angular']\n",
    "    df_action['w_min']=df_action.merge(train_seg.groupby(by='action_count')['vel_angular'].min(),left_on=['action_count'],right_index=True,how='left')['vel_angular']\n",
    "\n",
    "    df_action['curv_mean']=df_action.merge(train_seg.groupby(by='action_count')['curvat'].mean(),left_on=['action_count'],right_index=True,how='left')['curvat']\n",
    "    df_action['curv_std']=df_action.merge(train_seg.groupby(by='action_count')['curvat'].std(),left_on=['action_count'],right_index=True,how='left')['curvat']\n",
    "    df_action['curv_max']=df_action.merge(train_seg.groupby(by='action_count')['curvat'].max(),left_on=['action_count'],right_index=True,how='left')['curvat']\n",
    "    df_action['curv_min']=df_action.merge(train_seg.groupby(by='action_count')['curvat'].min(),left_on=['action_count'],right_index=True,how='left')['curvat']\n",
    "\n",
    "    df_action['action_type']=train_seg[train_seg.Action_border.notna()]['Action_border']\n",
    "    df_action['elapsed_time']=train_seg[train_seg.Action_border.notna()]['delta_action']\n",
    "    df_action['s_action']=train_seg[train_seg.Action_border.notna()]['cum_length']\n",
    "    df_action['dist_end_end']=Euclidean_Dist(train_seg.loc[train_seg['begin_act_idx'].unique(),['x','y']],\n",
    "    train_seg.loc[train_seg['end_act_idx'].unique(),['x','y']])\n",
    "    \n",
    "    vector_i_f=pd.DataFrame()\n",
    "    vector_i_f=(train_seg.loc[train_seg['end_act_idx'].unique(),['x','y']].reset_index()-train_seg.loc[train_seg['begin_act_idx'].unique(),['x','y']].reset_index())\n",
    "    vector_i_f['norm']=np.sqrt(vector_i_f['x']**2+vector_i_f['y']**2)\n",
    "\n",
    "    def get_angle(data):\n",
    "       if data['x']>=0  and data['y']>=0:\n",
    "          return np.arccos(np.divide(data['x'],data['norm']))\n",
    "       if data['x']<0  and data['y']>=0:\n",
    "          return np.arccos(np.divide(data['x'],data['norm']))\n",
    "       if data['x']<0  and data['y']<0:\n",
    "          return 2*np.pi-np.arccos(np.divide(data['x'],data['norm']))\n",
    "       if data['x']>=0 and data['y']<0:\n",
    "          return 2*np.pi-np.arccos(np.divide(data['x'],data['norm']))\n",
    "\n",
    "\n",
    "    def angle_to_direction(angle):\n",
    "       if angle <= np.radians(45):\n",
    "          return 1\n",
    "       elif angle <= np.radians(90):\n",
    "          return 2\n",
    "       elif angle <= np.radians(135):\n",
    "          return 3\n",
    "       elif angle <= np.radians(180):\n",
    "          return 4\n",
    "       elif angle <= np.radians(225):\n",
    "          return 5\n",
    "       elif angle <= np.radians(270):\n",
    "          return 6\n",
    "       elif angle <= np.radians(315):\n",
    "          return 7\n",
    "       else :\n",
    "          return 8\n",
    "    \n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "    #usar merge no ID\n",
    "    df_action['direction']=(vector_i_f.apply(get_angle,axis=1).fillna(0)).apply(angle_to_direction).values\n",
    "    df_action['straightness']=df_action['dist_end_end']/df_action['s_action']\n",
    "    df_action['num_points']=train_seg[train_seg.Action_border.notna()]['index']-train_seg[train_seg.Action_border.notna()]['index'].shift().fillna(train_seg[train_seg.Action_border.notna()]['index'].values[0])\n",
    "    df_action['sum_angle']= df_action.merge(train_seg.groupby(by='action_count')['theta'].sum(),left_on=['action_count'],right_index=True,how='left')['theta']\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_action['largest_deviation']=df_action.merge(train_seg.groupby(by='action_count')['deviation'].max(),left_on=['action_count'],right_index=True,how='left')['deviation']\n",
    "     \n",
    "    df_action['sharp angles']=df_action.merge(train_seg.groupby(by='action_count')['theta'].apply(lambda x: (x<=0.0005).sum()),left_on=['action_count'],right_index=True,how='left')['theta']\n",
    "    \n",
    "    #from inertia aceleration time\n",
    "    df_action.drop(['Unnamed: 0', 'record timestamp', 'client timestamp', 'button', 'state',\n",
    "       'x', 'y','Action', 'action_begin', 'delta_action',\n",
    "       'Action_border', 'begin_act_idx','act_correc_index'],inplace=True,axis=1)\n",
    "    return df_action,train_seg\n",
    "\n",
    "#obs:colocar essa função em novo notebook\n",
    "#df_action,train_seg=feat_eng(train_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-187-b1b4f9352c8d>:18: RuntimeWarning: invalid value encountered in true_divide\n",
      "  d = np.divide(d_ba, (np.hypot(d_ba[:, 0], d_ba[:, 1])\n",
      "<ipython-input-187-b1b4f9352c8d>:181: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.arccos(np.divide(data['x'],data['norm']))\n"
     ]
    }
   ],
   "source": [
    "train_seg=train_save\n",
    "df_action,train_seg=feat_eng(train_seg[train_seg.session=='session_5815391283'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Unnamed: 0.1         0\n",
       "session              0\n",
       "user                 0\n",
       "action_count         0\n",
       "index                0\n",
       "v_x_mean             0\n",
       "v_x_std              0\n",
       "v_x_max              0\n",
       "v_x_min              0\n",
       "v_y_mean             0\n",
       "v_y_std              0\n",
       "v_y_max              0\n",
       "v_y_min              0\n",
       "v_t_mean             0\n",
       "v_t_std              0\n",
       "v_t_max              0\n",
       "v_t_min              0\n",
       "acc_mean             0\n",
       "acc_std              0\n",
       "acc_max              0\n",
       "acc_min              0\n",
       "jerk_mean            0\n",
       "jerk_std             0\n",
       "jerk_max             0\n",
       "jerk_min             0\n",
       "w_mean               0\n",
       "w_std                0\n",
       "w_max                0\n",
       "w_min                0\n",
       "curv_mean            0\n",
       "curv_std             0\n",
       "curv_max             0\n",
       "curv_min             0\n",
       "action_type          0\n",
       "elapsed_time         0\n",
       "s_action             0\n",
       "dist_end_end         0\n",
       "direction            0\n",
       "straightness         0\n",
       "num_points           0\n",
       "sum_angle            0\n",
       "largest_deviation    0\n",
       "sharp angles         0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 189
    }
   ],
   "source": [
    "df_action.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       dist_end_end  s_action\n",
       "62605           0.0       0.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dist_end_end</th>\n      <th>s_action</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>62605</th>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "df_action[df_action.straightness.isna()][['dist_end_end','s_action']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'record timestamp',\n",
       "       'client timestamp', 'button', 'state', 'x', 'y', 'session', 'user',\n",
       "       'Action', 'action_begin', 'delta_action', 'Action_border',\n",
       "       'action_count', 'index', 'begin_act_idx', 'end_act_idx', 'delta_x',\n",
       "       'delta_y', 'deviation', 'dist_from_act_init', 'delta_t', 'vel_x',\n",
       "       'vel_x_delta', 'vel_y', 'vel_y_delta', 'vel_total', 'vel_tot_delta',\n",
       "       'theta', 'theta_delta', 'acc', 'acc_delta', 'jerk', 'vel_angular',\n",
       "       'event_length', 'cum_length', 'cum_length_delta', 'curvat'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "train_seg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         x    y  action_count Action_border\n",
       "62603  158  370           0.0          None\n",
       "62604  158  370           0.0          None\n",
       "62605  158  370           0.0            PC\n",
       "62606  160  370           1.0          None\n",
       "62607  161  371           1.0          None\n",
       "62608  163  373           1.0          None\n",
       "62609  198  383           1.0          None\n",
       "62610  287  403           1.0          None"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n      <th>y</th>\n      <th>action_count</th>\n      <th>Action_border</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>62603</th>\n      <td>158</td>\n      <td>370</td>\n      <td>0.0</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>62604</th>\n      <td>158</td>\n      <td>370</td>\n      <td>0.0</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>62605</th>\n      <td>158</td>\n      <td>370</td>\n      <td>0.0</td>\n      <td>PC</td>\n    </tr>\n    <tr>\n      <th>62606</th>\n      <td>160</td>\n      <td>370</td>\n      <td>1.0</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>62607</th>\n      <td>161</td>\n      <td>371</td>\n      <td>1.0</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>62608</th>\n      <td>163</td>\n      <td>373</td>\n      <td>1.0</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>62609</th>\n      <td>198</td>\n      <td>383</td>\n      <td>1.0</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>62610</th>\n      <td>287</td>\n      <td>403</td>\n      <td>1.0</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "train_seg.loc[:62610,:][['x','y','action_count','Action_border']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        action_count    cum_length\n",
       "62605            0.0  0.000000e+00\n",
       "62615            1.0  1.600504e+02\n",
       "62617            2.0  1.600504e+02\n",
       "62654            3.0  1.083187e+03\n",
       "62656            4.0  1.083187e+03\n",
       "...              ...           ...\n",
       "110771        1962.0  2.929095e+06\n",
       "110789        1963.0  2.929897e+06\n",
       "110818        1964.0  2.932426e+06\n",
       "110834        1965.0  2.933032e+06\n",
       "110846        1966.0  2.933243e+06\n",
       "\n",
       "[1967 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>action_count</th>\n      <th>cum_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>62605</th>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>62615</th>\n      <td>1.0</td>\n      <td>1.600504e+02</td>\n    </tr>\n    <tr>\n      <th>62617</th>\n      <td>2.0</td>\n      <td>1.600504e+02</td>\n    </tr>\n    <tr>\n      <th>62654</th>\n      <td>3.0</td>\n      <td>1.083187e+03</td>\n    </tr>\n    <tr>\n      <th>62656</th>\n      <td>4.0</td>\n      <td>1.083187e+03</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>110771</th>\n      <td>1962.0</td>\n      <td>2.929095e+06</td>\n    </tr>\n    <tr>\n      <th>110789</th>\n      <td>1963.0</td>\n      <td>2.929897e+06</td>\n    </tr>\n    <tr>\n      <th>110818</th>\n      <td>1964.0</td>\n      <td>2.932426e+06</td>\n    </tr>\n    <tr>\n      <th>110834</th>\n      <td>1965.0</td>\n      <td>2.933032e+06</td>\n    </tr>\n    <tr>\n      <th>110846</th>\n      <td>1966.0</td>\n      <td>2.933243e+06</td>\n    </tr>\n  </tbody>\n</table>\n<p>1967 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "train_seg[train_seg.Action_border.notnull()][['action_count','cum_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-76-7a93bbe42de9>:18: RuntimeWarning: invalid value encountered in true_divide\n",
      "  d = np.divide(d_ba, (np.hypot(d_ba[:, 0], d_ba[:, 1])\n",
      "<ipython-input-80-9171fe4c767d>:130: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.arccos(np.divide(data['x'],data['norm']))\n"
     ]
    }
   ],
   "source": [
    "train_seg=train_save\n",
    "temp=pd.DataFrame()\n",
    "#train_seg=train_seg[train_seg.session=='session_5265929106']\n",
    "temp=pd.DataFrame((train_seg[(train_seg.Action_border=='PC')| (train_seg.Action_border=='MM') | (train_seg.Action_border=='DD')].Action_border.index))\n",
    "temp['action_count']=temp.index\n",
    "temp['index']=temp.loc[:,0]\n",
    "temp.drop(0,axis=1,inplace= True)\n",
    "temp.set_index(temp['index'],inplace=True)\n",
    "temp.columns.name=None\n",
    "train_seg=train_seg.merge(temp,how='left',left_index=True, right_index=True)\n",
    "train_seg['action_count'].fillna(method='bfill',inplace=True)\n",
    "#train_seg.drop('index',axis=1,inplace=True)\n",
    "#2nd dataframe with action features\n",
    "df_action=train_seg[train_seg.Action_border.notna()].copy(deep=True)\n",
    "df_action['index']=train_seg[train_seg.Action_border.notna()].index\n",
    "df_action['begin_act_idx']=df_action['index'].shift()\n",
    "df_action['action_count']=train_seg['action_count']\n",
    "df_action.loc[df_action.index[0],'begin_act_idx']=train_seg.index[0]\n",
    "train_seg.loc[:,'begin_act_idx']=df_action['begin_act_idx']\n",
    "###########################################################\n",
    "#############################################################\n",
    "train_seg.loc[:,'begin_act_idx'].fillna(method='bfill',inplace=True)\n",
    "train_seg.loc[:,'end_act_idx']=df_action['index']\n",
    "train_seg.loc[:,'end_act_idx'].fillna(method='bfill',inplace=True)\n",
    "df_action.loc[df_action.index.to_list()[0],'begin_act_idx']=0\n",
    "#delta x,y, t\n",
    "train_seg['delta_x']=train_seg['x']-train_seg['x'].shift()\n",
    "train_seg['delta_y']=train_seg['y']-train_seg['y'].shift()\n",
    "train_seg.loc[train_seg.index[0],'delta_x']=0\n",
    "train_seg.loc[train_seg.index[0],'delta_y']=0\n",
    "    #print(train_seg.loc[:,'begin_act_idx'].values)\n",
    "    #train_seg['delta_x_begin_act']=np.sqrt((train_seg['x'].values-train_seg.loc[train_seg.loc[:,'begin_act_idx'].values,'x'].values)**2+(train_seg['y'].values-train_seg.loc[train_seg.loc[:,'begin_act_idx'].values,'y'].values)**2)\n",
    "    #train_seg['delta_x_end_act']=np.sqrt((train_seg['x'].values-train_seg.loc[train_seg.loc[:,'end_act_idx'].values,'x'].values)**2+(train_seg['y'].values-train_seg.loc[train_seg.loc[:,'end_act_idx'].values,'y'].values)**2)\n",
    "    #print(np.array(list(zip(train_seg.loc[train_seg.loc[:,'begin_act_idx'].values,'x'],train_seg.loc[train_seg.loc[:,'begin_act_idx'].values,'y']))))\n",
    "train_seg['deviation']=lineseg_dists(p=np.array(train_seg[['x','y']]),\n",
    "                                     a=np.array(list(zip(train_seg.loc[train_seg.loc[:,'begin_act_idx'].values,'x'],train_seg.loc[train_seg.loc[:,'begin_act_idx'].values,'y']))),\n",
    "                                     b=np.array(list(zip(train_seg.loc[train_seg.loc[:,'end_act_idx'].values,'x'],train_seg.loc[train_seg.loc[:,'end_act_idx'].values,'y']))))  \n",
    "\n",
    "train_seg['dist_from_act_init']=Euclidean_Dist(train_seg.loc[train_seg['begin_act_idx'],['x','y']],\n",
    "train_seg[['x','y']])\n",
    "train_seg.deviation.fillna(train_seg['dist_from_act_init'],inplace=True)\n",
    "\n",
    "\n",
    "#Tempo\n",
    "train_seg['delta_t']=(train_seg['client timestamp']-train_seg['client timestamp'].shift())\n",
    "train_seg['delta_t'].replace(0, train_seg[train_seg['delta_t']!=0].delta_t.min()/2,inplace=True)\n",
    "train_seg.loc[train_seg.index[0],'delta_t']=0\n",
    "\n",
    "#Velo\n",
    "train_seg['vel_x']=train_seg['delta_x']/train_seg['delta_t']\n",
    "train_seg.loc[train_seg.index[0],'vel_x']=0    \n",
    "train_seg['vel_x_delta']=train_seg['vel_x']-train_seg['vel_x'].shift()\n",
    "train_seg.loc[train_seg.index[0],'vel_x_delta']=0    \n",
    "#velocidades \n",
    "train_seg['vel_y']=train_seg['delta_y']/train_seg['delta_t']\n",
    "train_seg.loc[train_seg.index[0],'vel_y']=0    \n",
    "train_seg.loc[:,'vel_y'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "train_seg['vel_y_delta']=train_seg['vel_y']-train_seg['vel_y'].shift()\n",
    "train_seg.loc[train_seg.index[0],'vel_y_delta']=0    \n",
    "train_seg['vel_total']=np.sqrt(np.power(train_seg['vel_x'],2)+np.power(train_seg['vel_y'],2))\n",
    "train_seg.loc[train_seg.index[0],'vel_total']=0    \n",
    "train_seg['vel_tot_delta']=train_seg['vel_total']-train_seg['vel_total'].shift()\n",
    "train_seg.loc[train_seg.index[0],'vel_tot_delta']=0\n",
    "#theta coordenada angular\n",
    "train_seg['theta']=np.arctan(train_seg['delta_y']/train_seg['delta_x'])\n",
    "train_seg['theta'].replace(np.nan,0, inplace=True)\n",
    "train_seg.loc[train_seg.index[0],'theta']=0\n",
    "train_seg['theta_delta']=train_seg['theta']-train_seg['theta'].shift()\n",
    "train_seg.loc[train_seg.index[0],'theta_delta']=0 \n",
    "#extras\n",
    "train_seg['acc']=train_seg['vel_tot_delta']/train_seg['delta_t']\n",
    "train_seg.loc[train_seg.index[0],'acc']=0 \n",
    "train_seg['acc_delta']=train_seg['acc']-train_seg['acc'].shift()\n",
    "train_seg.loc[train_seg.index[0],'acc_delta']=0  \n",
    "train_seg['jerk']=train_seg['acc_delta']/train_seg['delta_t']\n",
    "train_seg.loc[train_seg.index[0],'jerk']=0\n",
    "#velocidade angular\n",
    "train_seg['vel_angular']=train_seg['theta_delta']/train_seg['delta_t']\n",
    "train_seg.loc[train_seg.index[0],'vel_angular']=0\n",
    "#Curvature\n",
    "train_seg['event_length']=np.sqrt(np.power(train_seg['delta_x'],2)+np.power(train_seg['delta_y'],2))\n",
    "train_seg['cum_length']=train_seg['event_length'].cumsum()  \n",
    "train_seg['cum_length_delta']=train_seg['cum_length']-train_seg['cum_length'].shift()\n",
    "train_seg.loc[train_seg.index[0],'cum_length_delta']=0   \n",
    "train_seg['curvat']=train_seg['theta_delta']/train_seg['delta_t']\n",
    "train_seg.loc[train_seg.index[0],'curvat']=0\n",
    "#Action Dataframe\n",
    "#df_action=train_seg[train_seg.Action_border.notna()].copy(deep=True)\n",
    "#df_action['begin_act_idx']=[0]+df_action.index.to_list()\n",
    "df_action['v_x_mean']=df_action.merge(train_seg.groupby(by='action_count')['vel_x'].mean(),left_on=['action_count'],right_index=True,how='left')['vel_x']\n",
    "df_action['v_x_std']=df_action.merge(train_seg.groupby(by='action_count')['vel_x'].std(),left_on=['action_count'],right_index=True,how='left')['vel_x']\n",
    "df_action['v_x_max']=df_action.merge(train_seg.groupby(by='action_count')['vel_x'].max(),left_on=['action_count'],right_index=True,how='left')['vel_x']\n",
    "df_action['v_x_min']=df_action.merge(train_seg.groupby(by='action_count')['vel_x'].min(),left_on=['action_count'],right_index=True,how='left')['vel_x']\n",
    "df_action['v_y_mean']=df_action.merge(train_seg.groupby(by='action_count')['vel_y'].mean(),left_on=['action_count'],right_index=True,how='left')['vel_y']\n",
    "df_action['v_y_std']=df_action.merge(train_seg.groupby(by='action_count')['vel_y'].std(),left_on=['action_count'],right_index=True,how='left')['vel_y']\n",
    "df_action['v_y_max']=df_action.merge(train_seg.groupby(by='action_count')['vel_y'].max(),left_on=['action_count'],right_index=True,how='left')['vel_y']\n",
    "df_action['v_y_min']=df_action.merge(train_seg.groupby(by='action_count')['vel_y'].min(),left_on=['action_count'],right_index=True,how='left')['vel_y']\n",
    "df_action['v_t_mean']=df_action.merge(train_seg.groupby(by='action_count')['vel_total'].mean(),left_on=['action_count'],right_index=True,how='left')['vel_total']\n",
    "df_action['v_t_std']=df_action.merge(train_seg.groupby(by='action_count')['vel_total'].std(),left_on=['action_count'],right_index=True,how='left')['vel_total']\n",
    "df_action['v_t_max']=df_action.merge(train_seg.groupby(by='action_count')['vel_total'].max(),left_on=['action_count'],right_index=True,how='left')['vel_total']\n",
    "df_action['v_t_min']=df_action.merge(train_seg.groupby(by='action_count')['vel_total'].min(),left_on=['action_count'],right_index=True,how='left')['vel_total'] \n",
    "df_action['acc_mean']=df_action.merge(train_seg.groupby(by='action_count')['acc'].mean(),left_on=['action_count'],right_index=True,how='left')['acc']\n",
    "df_action['acc_std']=df_action.merge(train_seg.groupby(by='action_count')['acc'].std(),left_on=['action_count'],right_index=True,how='left')['acc']\n",
    "df_action['acc_max']=df_action.merge(train_seg.groupby(by='action_count')['acc'].max(),left_on=['action_count'],right_index=True,how='left')['acc']\n",
    "df_action['acc_min']=df_action.merge(train_seg.groupby(by='action_count')['acc'].min(),left_on=['action_count'],right_index=True,how='left')['acc']\n",
    "df_action['jerk_mean']=df_action.merge(train_seg.groupby(by='action_count')['jerk'].mean(),left_on=['action_count'],right_index=True,how='left')['jerk']\n",
    "df_action['jerk_std']=df_action.merge(train_seg.groupby(by='action_count')['jerk'].std(),left_on=['action_count'],right_index=True,how='left')['jerk']\n",
    "df_action['jerk_max']=df_action.merge(train_seg.groupby(by='action_count')['jerk'].max(),left_on=['action_count'],right_index=True,how='left')['jerk']\n",
    "df_action['jerk_min']=df_action.merge(train_seg.groupby(by='action_count')['jerk'].min(),left_on=['action_count'],right_index=True,how='left')['jerk']\n",
    "df_action['w_mean']=df_action.merge(train_seg.groupby(by='action_count')['vel_angular'].mean(),left_on=['action_count'],right_index=True,how='left')['vel_angular']\n",
    "df_action['w_std']=df_action.merge(train_seg.groupby(by='action_count')['vel_angular'].std(),left_on=['action_count'],right_index=True,how='left')['vel_angular']\n",
    "df_action['w_max']=df_action.merge(train_seg.groupby(by='action_count')['vel_angular'].max(),left_on=['action_count'],right_index=True,how='left')['vel_angular']\n",
    "df_action['w_min']=df_action.merge(train_seg.groupby(by='action_count')['vel_angular'].min(),left_on=['action_count'],right_index=True,how='left')['vel_angular']\n",
    "df_action['curv_mean']=df_action.merge(train_seg.groupby(by='action_count')['curvat'].mean(),left_on=['action_count'],right_index=True,how='left')['curvat']\n",
    "df_action['curv_std']=df_action.merge(train_seg.groupby(by='action_count')['curvat'].std(),left_on=['action_count'],right_index=True,how='left')['curvat']\n",
    "df_action['curv_max']=df_action.merge(train_seg.groupby(by='action_count')['curvat'].max(),left_on=['action_count'],right_index=True,how='left')['curvat']\n",
    "df_action['curv_min']=df_action.merge(train_seg.groupby(by='action_count')['curvat'].min(),left_on=['action_count'],right_index=True,how='left')['curvat']\n",
    "df_action['action_type']=train_seg[train_seg.Action_border.notna()]['Action_border']\n",
    "df_action['elapsed_time']=train_seg[train_seg.Action_border.notna()]['delta_action']\n",
    "df_action['s_action']=train_seg[train_seg.Action_border.notna()]['cum_length']\n",
    "df_action['dist_end_end']=Euclidean_Dist(train_seg.loc[train_seg['begin_act_idx'].unique(),['x','y']],\n",
    "train_seg.loc[train_seg['end_act_idx'].unique(),['x','y']])\n",
    "\n",
    "vector_i_f=pd.DataFrame()\n",
    "vector_i_f=(train_seg.loc[train_seg['end_act_idx'].unique(),['x','y']].reset_index()-train_seg.loc[train_seg['begin_act_idx'].unique(),['x','y']].reset_index())\n",
    "vector_i_f['norm']=np.sqrt(vector_i_f['x']**2+vector_i_f['y']**2)\n",
    "\n",
    "def get_angle(data):\n",
    "   if data['x']>=0  and data['y']>=0:\n",
    "      return np.arccos(np.divide(data['x'],data['norm']))\n",
    "   if data['x']<0  and data['y']>=0:\n",
    "      return np.arccos(np.divide(data['x'],data['norm']))\n",
    "   if data['x']<0  and data['y']<0:\n",
    "      return 2*np.pi-np.arccos(np.divide(data['x'],data['norm']))\n",
    "   if data['x']>=0 and data['y']<0:\n",
    "      return 2*np.pi-np.arccos(np.divide(data['x'],data['norm']))\n",
    "def angle_to_direction(angle):\n",
    "   if angle <= np.radians(45):\n",
    "      return 1\n",
    "   elif angle <= np.radians(90):\n",
    "      return 2\n",
    "   elif angle <= np.radians(135):\n",
    "      return 3\n",
    "   elif angle <= np.radians(180):\n",
    "      return 4\n",
    "   elif angle <= np.radians(225):\n",
    "      return 5\n",
    "   elif angle <= np.radians(270):\n",
    "      return 6\n",
    "   elif angle <= np.radians(315):\n",
    "      return 7\n",
    "   else :\n",
    "      return 8\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#usar merge no ID\n",
    "df_action['direction']=(vector_i_f.apply(get_angle,axis=1).fillna(0)).apply(angle_to_direction)\n",
    "df_action['straightness']=df_action['dist_end_end']/df_action['s_action']\n",
    "df_action['num_points']=train_seg[train_seg.Action_border.notna()]['index']-train_seg[train_seg.Action_border.notna()]['index'].shift()\n",
    "df_action['sum_angle']= df_action.merge(train_seg.groupby(by='action_count')['theta'].sum(),left_on=['action_count'],right_index=True,how='left')['theta']\n",
    "    \n",
    "    \n",
    "    \n",
    "df_action['largest_deviation']=df_action.merge(train_seg.groupby(by='action_count')['deviation'].max(),left_on=['action_count'],right_index=True,how='left')['deviation']\n",
    "     \n",
    "df_action['sharp angles']=df_action.merge(train_seg.groupby(by='action_count')['theta'].apply(lambda x: (x<=0.0005).sum()),left_on=['action_count'],right_index=True,how='left') ['theta']\n",
    "    \n",
    "#from inertia aceleration time\n",
    "df_action.drop(['Unnamed: 0', 'record timestamp', 'client timestamp', 'button', 'state',\n",
    "    'x', 'y','Action', 'action_begin', 'delta_action',\n",
    "    'Action_border', 'begin_act_idx'],inplace=True,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "30292     NaN\n",
       "30297     5.0\n",
       "30299     2.0\n",
       "30323    24.0\n",
       "30333    10.0\n",
       "         ... \n",
       "62551    21.0\n",
       "62559     8.0\n",
       "62570    11.0\n",
       "62585    15.0\n",
       "62602    17.0\n",
       "Name: index, Length: 1482, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "train_seg[train_seg.Action_border.notna()]['index']-train_seg[train_seg.Action_border.notna()]['index'].shift().fillna(train_seg[train_seg.Action_border.notna()]['index'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "30292    30292.0\n",
       "30297    30297.0\n",
       "30299    30299.0\n",
       "30323    30323.0\n",
       "30333    30333.0\n",
       "          ...   \n",
       "62551    62551.0\n",
       "62559    62559.0\n",
       "62570    62570.0\n",
       "62585    62585.0\n",
       "62602    62602.0\n",
       "Name: index, Length: 1482, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "train_seg[train_seg.Action_border.notna()]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "30292    30292.0\n",
       "30297    30292.0\n",
       "30299    30297.0\n",
       "30323    30299.0\n",
       "30333    30323.0\n",
       "          ...   \n",
       "62551    62530.0\n",
       "62559    62551.0\n",
       "62570    62559.0\n",
       "62585    62570.0\n",
       "62602    62585.0\n",
       "Name: index, Length: 1482, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "train_seg[train_seg.Action_border.notna()]['index'].shift().fillna(train_seg[train_seg.Action_border.notna()]['index'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "30292.0"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "train_seg[train_seg.Action_border.notna()]['index'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}